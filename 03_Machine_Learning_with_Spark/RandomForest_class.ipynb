{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:23:40.221432",
     "start_time": "2017-10-28T09:23:40.217931"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load pyspark_init_mac.py\n",
    "#\n",
    "# This configuration works for Spark on macOS using homebrew\n",
    "#\n",
    "import os, sys\n",
    "# set OS environment variable\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/local/Cellar/apache-spark/2.2.0/libexec'\n",
    "# add Spark library to Python\n",
    "sys.path.insert(0, os.path.join(os.environ[\"SPARK_HOME\"], 'python'))\n",
    "\n",
    "# import package\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "\n",
    "import atexit\n",
    "def stop_my_spark():\n",
    "    sc.stop()\n",
    "    del(sc)\n",
    "\n",
    "# Register exit    \n",
    "atexit.register(stop_my_spark)\n",
    "\n",
    "# Configure and start Spark ... but only once.\n",
    "if not 'sc' in globals():\n",
    "    conf = SparkConf()\n",
    "    conf.setAppName('MyFirstSpark') ## you may want to change this\n",
    "    conf.setMaster('local[2]')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    print \"Launched Spark version %s with ID %s\" % (sc.version, sc.applicationId)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:22:01.742832",
     "start_time": "2017-10-28T09:22:01.739120"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "print sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the data file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:19:09.418405",
     "start_time": "2017-10-27T11:19:04.346936"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 items\n",
      "drwxr-xr-x   - pmolnar hdfs          0 2017-10-27 10:39 /data/apache-spark/mllib/als\n",
      "-rw-r--r--   3 pmolnar hdfs      63973 2017-10-27 10:39 /data/apache-spark/mllib/gmm_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs         72 2017-10-27 10:39 /data/apache-spark/mllib/kmeans_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs         24 2017-10-27 10:39 /data/apache-spark/mllib/pagerank_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs        164 2017-10-27 10:39 /data/apache-spark/mllib/pic_data.txt\n",
      "drwxr-xr-x   - pmolnar hdfs          0 2017-10-27 10:39 /data/apache-spark/mllib/ridge-data\n",
      "-rw-r--r--   3 pmolnar hdfs     104736 2017-10-27 10:39 /data/apache-spark/mllib/sample_binary_classification_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs         68 2017-10-27 10:39 /data/apache-spark/mllib/sample_fpgrowth.txt\n",
      "-rw-r--r--   3 pmolnar hdfs       1798 2017-10-27 10:39 /data/apache-spark/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs        120 2017-10-27 10:39 /data/apache-spark/mllib/sample_kmeans_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs        264 2017-10-27 10:39 /data/apache-spark/mllib/sample_lda_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs        578 2017-10-27 10:39 /data/apache-spark/mllib/sample_lda_libsvm_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs     104736 2017-10-27 10:39 /data/apache-spark/mllib/sample_libsvm_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs     119069 2017-10-27 10:39 /data/apache-spark/mllib/sample_linear_regression_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs      14351 2017-10-27 10:39 /data/apache-spark/mllib/sample_movielens_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs       6953 2017-10-27 10:39 /data/apache-spark/mllib/sample_multiclass_classification_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs      39474 2017-10-27 10:39 /data/apache-spark/mllib/sample_svm_data.txt\n",
      "-rw-r--r--   3 pmolnar hdfs         46 2017-10-27 10:39 /data/apache-spark/mllib/streaming_kmeans_data_test.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls /data/apache-spark/mllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to import a couple of modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:24:36.979152",
     "start_time": "2017-10-28T09:24:36.897851"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBSVM data format\n",
    "When I looked into LIBSVM data file for the first time, I got a little bit confused. But then I found its design is a brilliant idea.\n",
    "\n",
    "LIBSVM data files look like below:\n",
    "```\n",
    "-1 1:-766 2:128 3:0.140625 4:0.304688 5:0.234375 6:0.140625 7:0.304688 8:0.234375\n",
    "-1 1:-726 2:131 3:0.129771 4:0.328244 5:0.229008 6:0.129771 7:0.328244 8:0.229008\n",
    "......\n",
    "```\n",
    "The first element of each row is the *label*, or we can say it's the *response value*. The labels can be either discrete or continuous. Normally, the labels will be discrete if we're working on classification, and continuous if we're trying to do regression. Following the labels are the *feature indices* and the *feature values* in format `index:value` (Please note that the index starts from `1` instead of `0` in LIBSVM data files, i.e., the indices are one-based and in ascending order. After loading, the feature indices are converted to zero-based [4]).\n",
    "\n",
    "Sometimes we may find 'weird' LIBSVM data like below\n",
    "```\n",
    "-1 3:1 11:1 14:1 19:1 39:1 42:1 55:1 64:1 67:1 73:1 75:1 76:1 80:1 83:1 \n",
    "-1 3:1 6:1 17:1 27:1 35:1 40:1 57:1 63:1 69:1 73:1 74:1 76:1 81:1 103:1 \n",
    "-1 1:1 7:1 16:1 22:1 36:1 42:1 56:1 62:1 67:1 73:1 74:1 76:1 79:1 83:1 \n",
    "```\n",
    "The indices in it are not continuous. What's wrong? Actually the missing features are all 0. For example, in the first row, feature 1, 2, 4-10, 12-13, ... are all zero-values. This design is partially for the sake of memory usage. It would help improve the efficiency of the our programs if the data are sparse (containing quite many zero-values).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type \"Labeled Point\"\n",
    "\n",
    "The data loaded by method `loadLibSVMFile` will be saved as `Labeled Points`. What is it?\n",
    "\n",
    "MLlib supports local vectors and matrices stored on a single machine, as well as distributed matrices backed by one or more RDDs. Local vectors and local matrices are simple data models that serve as public interfaces. A training example used in supervised learning is called a “labeled point” in MLlib [4].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:24:53.361231",
     "start_time": "2017-10-28T09:24:50.320139"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = MLUtils.loadLibSVMFile(sc, '/data/apache-spark/mllib/sample_libsvm_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:32:06.353967",
     "start_time": "2017-10-27T15:32:06.228275"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "print type(data)\n",
    "f = data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:45:48.040771",
     "start_time": "2017-10-27T15:45:48.032377"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.regression.LabeledPoint'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabeledPoint(0.0, (692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(f)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:32:40.755534",
     "start_time": "2017-10-27T15:32:40.747784"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, float)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.label, type(f.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:33:24.290120",
     "start_time": "2017-10-27T15:33:24.253311"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.mllib.linalg.SparseVector,\n",
       " array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   51.,  159.,  253.,  159.,   50.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   48.,  238.,  252.,  252.,  252.,  237.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   54.,  227.,  253.,  252.,  239.,  233.,  252.,   57.,\n",
       "           6.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          10.,   60.,  224.,  252.,  253.,  252.,  202.,   84.,  252.,\n",
       "         253.,  122.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,  163.,  252.,  252.,  252.,  253.,  252.,  252.,   96.,\n",
       "         189.,  253.,  167.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   51.,  238.,  253.,  253.,  190.,  114.,  253.,  228.,\n",
       "          47.,   79.,  255.,  168.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   48.,  238.,  252.,  252.,  179.,   12.,   75.,  121.,\n",
       "          21.,    0.,    0.,  253.,  243.,   50.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   38.,  165.,  253.,  233.,  208.,   84.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,  253.,  252.,  165.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    7.,  178.,  252.,  240.,   71.,   19.,   28.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  253.,  252.,  195.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   57.,  252.,  252.,   63.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  253.,  252.,  195.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,  198.,  253.,  190.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,  255.,  253.,\n",
       "         196.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   76.,  246.,  252.,  112.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  253.,\n",
       "         252.,  148.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,   85.,  252.,  230.,   25.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    7.,  135.,\n",
       "         253.,  186.,   12.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   85.,  252.,  223.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    7.,  131.,\n",
       "         252.,  225.,   71.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,   85.,  252.,  145.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,   48.,  165.,\n",
       "         252.,  173.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,   86.,  253.,\n",
       "         225.,    0.,    0.,    0.,    0.,    0.,    0.,  114.,  238.,\n",
       "         253.,  162.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   85.,\n",
       "         252.,  249.,  146.,   48.,   29.,   85.,  178.,  225.,  253.,\n",
       "         223.,  167.,   56.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          85.,  252.,  252.,  252.,  229.,  215.,  252.,  252.,  252.,\n",
       "         196.,  130.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   28.,  199.,  252.,  252.,  253.,  252.,  252.,  233.,\n",
       "         145.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   25.,  128.,  252.,  253.,  252.,  141.,\n",
       "          37.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f.features), f.features.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:33:07.988174",
     "start_time": "2017-10-28T09:33:07.914454"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(False, 0.1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:28:14.958413",
     "start_time": "2017-10-28T09:28:14.723510"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70 9 21\n"
     ]
    }
   ],
   "source": [
    "(trainingData, validationData, testData) = data.randomSplit([70, 10, 20])\n",
    "print trainingData.count(), validationData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:23:58.790180",
     "start_time": "2017-10-27T11:23:58.785064"
    }
   },
   "source": [
    "## How many trees we should have (`numTrees`)\n",
    "\n",
    "This argument determines how many trees we build in a random forest. Increasing the number of trees will decrease the variance in predictions, and improve the model’s test accuracy. At the same time, training time will increaseroughly linearly in the number of trees.\n",
    "\n",
    "Personally, I would recommend 400-500 as a 'safe' choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many features to use (`featureSubsetStrategy`)\n",
    "\n",
    "As we mentioned above, the very unique charactristic of *random forest* is that in each split of the tree model we use a subset of features (predictors) instead of using all of them. Then, how many features should we use in each split? we can set `featureSubsetStrategy=\"auto\"` of course so that the function we called will help us configure automatically, but we may want to tune it in some situations. Decreasing this number will speed up training, but can sometimes impact performance if too low [2].\n",
    "\n",
    "For the function `RandomForest.trainClassifier` in PySaprk , argument `featureSubsetStrategy` supports“auto” (default), “all”, “sqrt”, “log2”, “onethird”. If “auto” is set, this parameter is set based on numTrees: if numTrees == 1, set to “all”; if numTrees > 1 (forest) set to “sqrt” [3].\n",
    "\n",
    "Usually, given the number of features is `p`, we use `p/3` features in each model when building a random forest for regression, and use `sqrt(p)` features in each model if a random forest is built for classification [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is 'gini' --- the measures used to grow the trees (`impurity`)\n",
    "\n",
    "`impurity` argument helps determine the criterion used for information gain calculation, and in PySpark the supported values are “gini” (recommended) or “entropy” [3]. Since random forest is some kind of *greedy algorithm*, we can say that `impurity` helps determine what is the objective function when the algorithm makes each decisions.\n",
    "\n",
    "The most commonly used measures for this are just **Gini Index** and *Cross-entropy*, corresponding to the two supported values for `impurity` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:51:31.074935",
     "start_time": "2017-10-27T15:51:29.742546"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:52:49.711575",
     "start_time": "2017-10-27T15:52:49.705027"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.features.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:52:02.250328",
     "start_time": "2017-10-27T15:52:02.244849"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 433 <= 0.0)\n",
      "     If (feature 574 <= 253.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 574 > 253.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 433 > 0.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 346 <= 4.0)\n",
      "     If (feature 568 <= 47.0)\n",
      "      If (feature 416 <= 0.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 416 > 0.0)\n",
      "       Predict: 0.0\n",
      "     Else (feature 568 > 47.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 346 > 4.0)\n",
      "     Predict: 0.0\n",
      "  Tree 2:\n",
      "    If (feature 605 <= 0.0)\n",
      "     If (feature 379 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 379 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 605 > 0.0)\n",
      "     If (feature 243 <= 0.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 243 > 0.0)\n",
      "      If (feature 154 <= 0.0)\n",
      "       If (feature 624 <= 253.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 624 > 253.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 154 > 0.0)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print model.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Let's apply our model on the test set, and see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:56:16.314466",
     "start_time": "2017-10-27T15:56:16.151276"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "predictions.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T15:56:49.475852",
     "start_time": "2017-10-27T15:56:49.290148"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "labelsAndPredictions.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:27:44.340718",
     "start_time": "2017-10-27T11:27:43.920718"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0967741935484\n",
      "Learned classification forest model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 456 <= 0.0)\n",
      "     If (feature 213 <= 254.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 213 > 254.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 456 > 0.0)\n",
      "     Predict: 0.0\n",
      "  Tree 1:\n",
      "    If (feature 540 <= 65.0)\n",
      "     Predict: 1.0\n",
      "    Else (feature 540 > 65.0)\n",
      "     Predict: 0.0\n",
      "  Tree 2:\n",
      "    If (feature 385 <= 0.0)\n",
      "     If (feature 439 <= 0.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 439 > 0.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 385 > 0.0)\n",
      "     Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "print 'Test Error = ' + str(testErr)\n",
    "print 'Learned classification forest model:'\n",
    "print model.toDebugString() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:29:51.273767",
     "start_time": "2017-10-27T11:29:51.169920"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = testData.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:29:57.615220",
     "start_time": "2017-10-27T11:29:57.610597"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.mllib.regression.LabeledPoint"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:30:41.146390",
     "start_time": "2017-10-27T11:30:41.104089"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,  124.,  253.,  255.,   63.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   96.,  244.,  251.,  253.,\n",
       "         62.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,  127.,  251.,  251.,\n",
       "        253.,   62.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,   68.,  236.,  251.,\n",
       "        211.,   31.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,   60.,  228.,  251.,\n",
       "        251.,   94.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,  155.,  253.,\n",
       "        253.,  189.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,   20.,  253.,\n",
       "        251.,  235.,   66.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,   32.,  205.,\n",
       "        253.,  251.,  126.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  104.,\n",
       "        251.,  253.,  184.,   15.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   80.,\n",
       "        240.,  251.,  193.,   23.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   32.,\n",
       "        253.,  253.,  253.,  159.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        151.,  251.,  251.,  251.,   39.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         48.,  221.,  251.,  251.,  172.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,  234.,  251.,  251.,  196.,   12.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,  253.,  251.,  251.,   89.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,  159.,  255.,  253.,  253.,   31.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   48.,  228.,  253.,  247.,  140.,    8.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,   64.,  251.,  253.,  220.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,   64.,  251.,  253.,  220.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   24.,  193.,  253.,  220.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.features.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Bank Data Example\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/bank+marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where out data file is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:52:05.857121",
     "start_time": "2017-10-27T11:52:00.809451"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - pmolnar hdfs          0 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing\n",
      "-rw-r--r--   3 pmolnar hdfs        271 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/README.txt\n",
      "-rw-r--r--   3 pmolnar hdfs    5834924 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-additional-full.csv\n",
      "-rw-r--r--   3 pmolnar hdfs       5458 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-additional-names.txt\n",
      "-rw-r--r--   3 pmolnar hdfs     583898 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-additional.csv\n",
      "-rw-r--r--   3 pmolnar hdfs    4610348 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-full.csv\n",
      "-rw-r--r--   3 pmolnar hdfs       3864 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-names.txt\n",
      "-rw-r--r--   3 pmolnar hdfs     461474 2017-10-27 11:45 /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls -R /data/apache-spark/archive.ics.uci.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:40:53.291761",
     "start_time": "2017-10-28T09:40:47.880973"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "44;\"technician\";\"single\";\"secondary\";\"no\";29;\"yes\";\"no\";\"unknown\";5;\"may\";151;1;-1;0;\"unknown\";\"no\"\n",
      "33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2;\"yes\";\"yes\";\"unknown\";5;\"may\";76;1;-1;0;\"unknown\";\"no\"\n",
      "47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506;\"yes\";\"no\";\"unknown\";5;\"may\";92;1;-1;0;\"unknown\";\"no\"\n",
      "33;\"unknown\";\"single\";\"unknown\";\"no\";1;\"no\";\"no\";\"unknown\";5;\"may\";198;1;-1;0;\"unknown\";\"no\"\n",
      "35;\"management\";\"married\";\"tertiary\";\"no\";231;\"yes\";\"no\";\"unknown\";5;\"may\";139;1;-1;0;\"unknown\";\"no\"\n",
      "28;\"management\";\"single\";\"tertiary\";\"no\";447;\"yes\";\"yes\";\"unknown\";5;\"may\";217;1;-1;0;\"unknown\";\"no\"\n",
      "42;\"entrepreneur\";\"divorced\";\"tertiary\";\"yes\";2;\"yes\";\"no\";\"unknown\";5;\"may\";380;1;-1;0;\"unknown\";\"no\"\n",
      "58;\"retired\";\"married\";\"primary\";\"no\";121;\"yes\";\"no\";\"unknown\";5;\"may\";50;1;-1;0;\"unknown\";\"no\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -cat /data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-full.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to load the data set as DataFrame (not RDD) and then create LabeledPoint objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:50:09.928015",
     "start_time": "2017-10-27T11:50:09.924615"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, HiveContext, Row\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:46:45.522523",
     "start_time": "2017-10-28T09:46:45.519320"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAFILE = '/data/apache-spark/archive.ics.uci.edu/BankMarketing/bank-additional-full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:58:52.093793",
     "start_time": "2017-10-28T09:58:52.010646"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile(DATAFILE).map(lambda r: r.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:58:55.732337",
     "start_time": "2017-10-28T09:58:55.606762"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'age;job;marital;education;default;housing;loan;contact;month;day_of_week;duration;campaign;pdays;previous;poutcome;emp.var.rate;cons.price.idx;cons.conf.idx;euribor3m;nr.employed;y',\n",
       " u'56;housemaid;married;basic.4y;no;no;no;telephone;may;mon;261;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'57;services;married;high.school;unknown;no;no;telephone;may;mon;149;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'37;services;married;high.school;no;yes;no;telephone;may;mon;226;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'40;admin.;married;basic.6y;no;no;no;telephone;may;mon;151;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'56;services;married;high.school;no;no;yes;telephone;may;mon;307;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'45;services;married;basic.9y;unknown;no;no;telephone;may;mon;198;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'59;admin.;married;professional.course;no;no;no;telephone;may;mon;139;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'41;blue-collar;married;unknown;unknown;no;no;telephone;may;mon;217;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'24;technician;single;professional.course;no;yes;no;telephone;may;mon;380;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the top row and use for column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:59:06.507340",
     "start_time": "2017-10-28T09:59:06.308321"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'56;housemaid;married;basic.4y;no;no;no;telephone;may;mon;261;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'57;services;married;high.school;unknown;no;no;telephone;may;mon;149;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'37;services;married;high.school;no;yes;no;telephone;may;mon;226;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no',\n",
       " u'40;admin.;married;basic.6y;no;no;no;telephone;may;mon;151;1;999;0;nonexistent;1.1;93.994;-36.4;4.857;5191;no']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_row = rdd.take(1)[0]\n",
    "rdd2 = rdd.filter(lambda row: row!=top_row)\n",
    "rdd2.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:59:10.769158",
     "start_time": "2017-10-28T09:59:10.695526"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'56',\n",
       "  u'housemaid',\n",
       "  u'married',\n",
       "  u'basic.4y',\n",
       "  u'no',\n",
       "  u'no',\n",
       "  u'no',\n",
       "  u'telephone',\n",
       "  u'may',\n",
       "  u'mon',\n",
       "  u'261',\n",
       "  u'1',\n",
       "  u'999',\n",
       "  u'0',\n",
       "  u'nonexistent',\n",
       "  u'1.1',\n",
       "  u'93.994',\n",
       "  u'-36.4',\n",
       "  u'4.857',\n",
       "  u'5191',\n",
       "  u'no')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = rdd2.map(lambda r: tuple(r.split(';')))\n",
    "rdd3.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T09:59:15.876746",
     "start_time": "2017-10-28T09:59:15.868099"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'age',\n",
       " u'job',\n",
       " u'marital',\n",
       " u'education',\n",
       " u'default',\n",
       " u'housing',\n",
       " u'loan',\n",
       " u'contact',\n",
       " u'month',\n",
       " u'day_of_week',\n",
       " u'duration',\n",
       " u'campaign',\n",
       " u'pdays',\n",
       " u'previous',\n",
       " u'poutcome',\n",
       " u'emp.var.rate',\n",
       " u'cons.price.idx',\n",
       " u'cons.conf.idx',\n",
       " u'euribor3m',\n",
       " u'nr.employed',\n",
       " u'y']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = top_row.split(';')\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating  a Table (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:04:08.541891",
     "start_time": "2017-10-28T10:04:08.538147"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:04:10.740732",
     "start_time": "2017-10-28T10:04:10.737024"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = T.StructType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:04:28.100378",
     "start_time": "2017-10-28T10:04:27.990854"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 age 56\n",
      "1 job housemaid\n",
      "2 marital married\n",
      "3 education basic.4y\n",
      "4 default no\n",
      "5 housing no\n",
      "6 loan no\n",
      "7 contact telephone\n",
      "8 month may\n",
      "9 day_of_week mon\n",
      "10 duration 261\n",
      "11 campaign 1\n",
      "12 pdays 999\n",
      "13 previous 0\n",
      "14 poutcome nonexistent\n",
      "15 emp.var.rate 1.1\n",
      "16 cons.price.idx 93.994\n",
      "17 cons.conf.idx -36.4\n",
      "18 euribor3m 4.857\n",
      "19 nr.employed 5191\n",
      "20 y no\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "float_patt = re.compile(r'^-{0,1}\\d+\\.')\n",
    "int_patt = re.compile(r'^-{0,1}\\d+')\n",
    "two_rows = rdd.map(lambda r: r.split(';')).take(2)\n",
    "for i in range(len(two_rows[0])):\n",
    "    print i, two_rows[0][i], two_rows[1][i]\n",
    "    if float_patt.match(two_rows[1][i]):\n",
    "        schema.add(T.StructField(name=two_rows[0][i], dataType=T.FloatType(), nullable=True))\n",
    "    elif int_patt.match(two_rows[1][i]):\n",
    "        schema.add(T.StructField(name=two_rows[0][i], dataType=T.IntegerType(), nullable=True))\n",
    "    else:\n",
    "        schema.add(T.StructField(name=two_rows[0][i], dataType=T.StringType(), nullable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:04:43.247162",
     "start_time": "2017-10-28T10:04:43.242212"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(age,IntegerType,true),StructField(job,StringType,true),StructField(marital,StringType,true),StructField(education,StringType,true),StructField(default,StringType,true),StructField(housing,StringType,true),StructField(loan,StringType,true),StructField(contact,StringType,true),StructField(month,StringType,true),StructField(day_of_week,StringType,true),StructField(duration,IntegerType,true),StructField(campaign,IntegerType,true),StructField(pdays,IntegerType,true),StructField(previous,IntegerType,true),StructField(poutcome,StringType,true),StructField(emp.var.rate,FloatType,true),StructField(cons.price.idx,FloatType,true),StructField(cons.conf.idx,FloatType,true),StructField(euribor3m,FloatType,true),StructField(nr.employed,IntegerType,true),StructField(y,StringType,true)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:09:08.306004",
     "start_time": "2017-10-28T10:08:56.260852"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: float (nullable = true)\n",
      " |-- cons.price.idx: float (nullable = true)\n",
      " |-- cons.conf.idx: float (nullable = true)\n",
      " |-- euribor3m: float (nullable = true)\n",
      " |-- nr.employed: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlCtx.createDataFrame(rdd2.map(lambda r: tuple(r.split(';'))), schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:10:08.985994",
     "start_time": "2017-10-28T10:10:07.463914"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         job  marital            education default housing loan  \\\n",
       "0  None      admin.  married             basic.9y      no     yes   no   \n",
       "1  None  technician   single    university.degree      no     yes   no   \n",
       "2  None    services  married    university.degree      no      no   no   \n",
       "3  None  technician   single  professional.course      no     yes   no   \n",
       "4  None      admin.  married    university.degree      no     yes   no   \n",
       "5  None  technician   single          high.school      no     yes  yes   \n",
       "6  None  technician   single    university.degree      no      no   no   \n",
       "7  None  management  married             basic.9y      no     yes   no   \n",
       "8  None  technician   single    university.degree      no      no  yes   \n",
       "9  None  technician  married  professional.course      no      no   no   \n",
       "\n",
       "    contact month day_of_week ...  campaign pdays previous     poutcome  \\\n",
       "0  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "1  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "2  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "3  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "4  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "5  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "6  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "7  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "8  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "9  cellular   aug         tue ...      None  None     None  nonexistent   \n",
       "\n",
       "  emp.var.rate cons.price.idx cons.conf.idx euribor3m nr.employed    y  \n",
       "0         None           None          None      None        None   no  \n",
       "1         None           None          None      None        None  yes  \n",
       "2         None           None          None      None        None   no  \n",
       "3         None           None          None      None        None  yes  \n",
       "4         None           None          None      None        None   no  \n",
       "5         None           None          None      None        None  yes  \n",
       "6         None           None          None      None        None   no  \n",
       "7         None           None          None      None        None   no  \n",
       "8         None           None          None      None        None  yes  \n",
       "9         None           None          None      None        None   no  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning something about the DataFrame\n",
    "http://spark.apache.org/docs/1.6.1/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:12:02.379516",
     "start_time": "2017-10-28T10:12:02.374664"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable('worldbank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:15:17.648782",
     "start_time": "2017-10-28T10:15:16.465852"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|    N|\n",
      "+---+-----+\n",
      "| no|36548|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "SELECT y, COUNT(*) AS N\n",
    "FROM worldbank\n",
    "GROUP BY y\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:16:40.491646",
     "start_time": "2017-10-28T11:16:40.484296"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- education: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.education).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:13:58.592806",
     "start_time": "2017-10-28T11:13:56.980367"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">count(y)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th>basic.4y</th>\n",
       "      <th>basic.6y</th>\n",
       "      <th>basic.9y</th>\n",
       "      <th>high.school</th>\n",
       "      <th>illiterate</th>\n",
       "      <th>professional.course</th>\n",
       "      <th>university.degree</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>3748</td>\n",
       "      <td>2104</td>\n",
       "      <td>5572</td>\n",
       "      <td>8484</td>\n",
       "      <td>14</td>\n",
       "      <td>4648</td>\n",
       "      <td>10498</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>428</td>\n",
       "      <td>188</td>\n",
       "      <td>473</td>\n",
       "      <td>1031</td>\n",
       "      <td>4</td>\n",
       "      <td>595</td>\n",
       "      <td>1670</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count(y)                                           \\\n",
       "education basic.4y basic.6y basic.9y high.school illiterate   \n",
       "y                                                             \n",
       "no            3748     2104     5572        8484         14   \n",
       "yes            428      188      473        1031          4   \n",
       "\n",
       "                                                         \n",
       "education professional.course university.degree unknown  \n",
       "y                                                        \n",
       "no                       4648             10498    1480  \n",
       "yes                       595              1670     251  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_education_pdf = df.groupBy(['education', 'y']).agg({'y':'count'}).sort('education', 'y').toPandas()\n",
    "agg_education_pdf.pivot_table(index='y', columns='education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T10:21:52.904514",
     "start_time": "2017-10-28T10:21:52.880735"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age', 'education', 'y').printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:48:55.874216",
     "start_time": "2017-10-28T11:48:55.683606"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "def prepareFeatures(df, label_col, featr_col):\n",
    "    \n",
    "    def gettypes(df):\n",
    "        d = {}\n",
    "        for t in df.dtypes:\n",
    "            d[t[0]] = t[1]\n",
    "        return d\n",
    "\n",
    "    df_types = gettypes(df)\n",
    "\n",
    "    ## process label\n",
    "    if df_types[label_col]=='string':\n",
    "        lbl_indexer = StringIndexer(inputCol=label_col, outputCol='label')\n",
    "        df_tmp = lbl_indexer.fit(df).transform(df)\n",
    "    else:\n",
    "        ### assume is fine ...\n",
    "        df_tmp = df.withColumn('label', F.col(label_col).cast('float'))\n",
    "        \n",
    "    fv_cols = []\n",
    "    ## process categorical cols... there are strings\n",
    "    featr_string_col = filter(lambda s: df_types[s]=='string', featr_col)\n",
    "    \n",
    "    for ftr in featr_string_col:\n",
    "        print \"Process feature '%s'\"%str(ftr)\n",
    "        indexer = StringIndexer(inputCol=ftr, outputCol=ftr+'_IDX')\n",
    "        df_tmp = indexer.fit(df_tmp).transform(df_tmp)\n",
    "        encoder = OneHotEncoder(dropLast=False, inputCol=ftr+'_IDX', outputCol=ftr+'_FV')\n",
    "        df_tmp = encoder.transform(df_tmp)\n",
    "        fv_cols += [ftr+'_FV']\n",
    "    \n",
    "    ## process other types...\n",
    "    ## doing nothing here right now, but if: make sure to add names to `fv_cols`\n",
    "        \n",
    "    ## combine all feature vectors into one column `features`\n",
    "    \n",
    "    assembler_features = VectorAssembler(inputCols=fv_cols, outputCol='features')\n",
    "    df_tmp = assembler_features.transform(df_tmp)\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:49:25.695923",
     "start_time": "2017-10-28T11:49:24.944144"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process feature 'education'\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: float (nullable = true)\n",
      " |-- cons.price.idx: float (nullable = true)\n",
      " |-- cons.conf.idx: float (nullable = true)\n",
      " |-- euribor3m: float (nullable = true)\n",
      " |-- nr.employed: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- education_IDX: double (nullable = true)\n",
      " |-- education_FV: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = prepareFeatures(df, 'y', ['age', 'education'])\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:52:41.842728",
     "start_time": "2017-10-28T11:52:41.241446"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>high.school</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>high.school</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>high.school</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>high.school</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y   age            education  label  \\\n",
       "0  no  None             basic.4y    0.0   \n",
       "1  no  None          high.school    0.0   \n",
       "2  no  None          high.school    0.0   \n",
       "3  no  None             basic.6y    0.0   \n",
       "4  no  None          high.school    0.0   \n",
       "5  no  None             basic.9y    0.0   \n",
       "6  no  None  professional.course    0.0   \n",
       "7  no  None              unknown    0.0   \n",
       "8  no  None  professional.course    0.0   \n",
       "9  no  None          high.school    0.0   \n",
       "\n",
       "                                   features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  \n",
       "1  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "2  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0)  \n",
       "4  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "5  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "6  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)  \n",
       "8  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0)  \n",
       "9  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select('y', 'age', 'education', 'label', 'features').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:42:16.507051",
     "start_time": "2017-10-28T11:42:16.501994"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gettypes(df):\n",
    "    d = {}\n",
    "    for t in df.dtypes:\n",
    "        d[t[0]] = t[1]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:42:24.264908",
     "start_time": "2017-10-28T11:42:24.258539"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 'int',\n",
       " 'campaign': 'int',\n",
       " 'cons.conf.idx': 'float',\n",
       " 'cons.price.idx': 'float',\n",
       " 'contact': 'string',\n",
       " 'day_of_week': 'string',\n",
       " 'default': 'string',\n",
       " 'duration': 'int',\n",
       " 'education': 'string',\n",
       " 'emp.var.rate': 'float',\n",
       " 'euribor3m': 'float',\n",
       " 'housing': 'string',\n",
       " 'job': 'string',\n",
       " 'loan': 'string',\n",
       " 'marital': 'string',\n",
       " 'month': 'string',\n",
       " 'nr.employed': 'int',\n",
       " 'pdays': 'int',\n",
       " 'poutcome': 'string',\n",
       " 'previous': 'int',\n",
       " 'y': 'string'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:55:23.290705",
     "start_time": "2017-10-28T11:55:23.287068"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepareFeatures(df, 'y', ['age', 'job', 'marital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:58:04.443726",
     "start_time": "2017-10-28T11:58:00.052730"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process feature 'job'\n",
      "Process feature 'marital'\n",
      "Process feature 'education'\n",
      "Process feature 'default'\n",
      "Process feature 'housing'\n",
      "Process feature 'loan'\n",
      "Process feature 'contact'\n",
      "Process feature 'month'\n",
      "Process feature 'day_of_week'\n",
      "Process feature 'poutcome'\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: float (nullable = true)\n",
      " |-- cons.price.idx: float (nullable = true)\n",
      " |-- cons.conf.idx: float (nullable = true)\n",
      " |-- euribor3m: float (nullable = true)\n",
      " |-- nr.employed: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- job_IDX: double (nullable = true)\n",
      " |-- job_FV: vector (nullable = true)\n",
      " |-- marital_IDX: double (nullable = true)\n",
      " |-- marital_FV: vector (nullable = true)\n",
      " |-- education_IDX: double (nullable = true)\n",
      " |-- education_FV: vector (nullable = true)\n",
      " |-- default_IDX: double (nullable = true)\n",
      " |-- default_FV: vector (nullable = true)\n",
      " |-- housing_IDX: double (nullable = true)\n",
      " |-- housing_FV: vector (nullable = true)\n",
      " |-- loan_IDX: double (nullable = true)\n",
      " |-- loan_FV: vector (nullable = true)\n",
      " |-- contact_IDX: double (nullable = true)\n",
      " |-- contact_FV: vector (nullable = true)\n",
      " |-- month_IDX: double (nullable = true)\n",
      " |-- month_FV: vector (nullable = true)\n",
      " |-- day_of_week_IDX: double (nullable = true)\n",
      " |-- day_of_week_FV: vector (nullable = true)\n",
      " |-- poutcome_IDX: double (nullable = true)\n",
      " |-- poutcome_FV: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_proc = prepareFeatures(df, 'y', columns[:-1])\n",
    "df_proc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T11:58:34.938180",
     "start_time": "2017-10-28T11:58:34.436860"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "numClasses = int(df_proc.agg(F.max('label')).collect()[0][0])+1\n",
    "print numClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-28T12:04:12.259807",
     "start_time": "2017-10-28T12:03:14.652081"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+---+\n",
      "|label|    0|  1|\n",
      "+-----+-----+---+\n",
      "|    0|10728|118|\n",
      "|    1| 1083|246|\n",
      "+-----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_proc.randomSplit([0.7, 0.3])\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "##from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier( numTrees=100, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=10, maxBins=32)\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "result = model.transform(testData)\n",
    "result.prediction\n",
    "\n",
    "result.select('label', 'prediction').show()\n",
    "#cm = res.groupBy('label').pivot('prediction').sum('one')\n",
    "#\n",
    "\n",
    "res = result.select(F.col('label').cast('int'), F.col('prediction').cast('int')).withColumn('one', F.lit(1))\n",
    "\n",
    "cm = res.groupBy('label').pivot('prediction').sum('one')\n",
    "cm.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "#predictions = model.predict(testData.map(lambda x: x.features))\n",
    "#labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "#testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "#print('Test Error = ' + str(testErr))\n",
    "#print('Learned classification forest model:')\n",
    "#print(model.toDebugString())\n",
    "\n",
    "# Save and load model\n",
    "#model.save(sc, \"target/tmp/myRandomForestClassificationModel\")\n",
    "#sameModel = RandomForestModel.load(sc, \"target/tmp/myRandomForestClassificationModel\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "PySpark 1.6.1 - Cluster",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "toc": {
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
