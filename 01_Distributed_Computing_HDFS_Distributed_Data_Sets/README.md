# Session  1
## Distributed Computing, HDFS, Distributed Data Sets
| Date | Time |
|------|------|
|  Friday, 10/20    |  1:00 - 4:00 PM       



### Objectives of this session
1. Challenges of parallel distributed computing and the map-reduce concept
1. Introduce the concept of RDDs (Resilient Distributed Datasets), and the principle of 'transformations' and 'actions'
2. Run and monitor Spark processes (on the cluster, as well as in other environments)


### Resources
1. [Apache Spark Documentation](http://spark.apache.org/documentation.html)
2. [Spark - A visual guide to the API](http://training.databricks.com/visualapi.pdf)
3. [Scala Documentation](http://docs.scala-lang.org/index.html)
