{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 200%; font-weight: bold; color: gray; padding-bottom: 20px\">Loading Data into Hive</div>\n",
    "Our Yelp data sets are stored in JSON format. They include nested structures which cannot be directly translated into SQL/Hive tables.\n",
    "\n",
    "In some cases we have to produce multiple tables from a single data set and then join them in queries. Alternatively, we may have to replicate certain values across rows to generate a \"flat\" table. Sometimes *proper database normalization* and a*nalysis tools* are at odds...\n",
    "\n",
    "To learn more about database normalization go to https://en.wikipedia.org/wiki/Database_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:59:44.291141",
     "start_time": "2017-01-21T08:59:44.240001"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext sql\n",
    "%config SqlMagic.autolimit=200\n",
    "%config SqlMagic.displaylimit=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:31:52.866756",
     "start_time": "2017-01-21T00:31:52.632800"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>tab_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>users</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'users',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql hive://backend-0-1:10000/pmolnar\n",
    "SHOW TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'user' data set\n",
    "\n",
    "The JSON schema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "    'type': 'user',\n",
    "    'user_id': (encrypted user id),\n",
    "    'name': (first name),\n",
    "    'review_count': (review count),\n",
    "    'average_stars': (floating point average, like 4.31),\n",
    "    'votes': {(vote type): (count)},\n",
    "    'friends': [(friend user_ids)],\n",
    "    'elite': [(years_elite)],\n",
    "    'yelping_since': (date, formatted like '2012-03'),\n",
    "    'compliments': {\n",
    "        (compliment_type): (num_compliments_of_this_type),\n",
    "        ...\n",
    "    },\n",
    "    'fans': (num_fans),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized tables\n",
    "### Table: **users**\n",
    "\n",
    "|user_id|name|review_count|average_stars|yelping_since|fans|\n",
    "|-------|----|------------|-------------|-------------|----| \n",
    "| x | x |x  | x | x | x |\n",
    "| x | x |x  | x | x | x |\n",
    "| x | x |x  | x | x | x |\n",
    "\n",
    "### Table: **user_votes**\n",
    "\n",
    "|user_id|vote_type|count|\n",
    "|-------|---------|-----|\n",
    "| x| x | x |\n",
    "| x| x | x |\n",
    "| x| x | x |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: **user_friends**\n",
    "\n",
    "|user_id|friends_user_id|\n",
    "|-------|---------------|\n",
    "| x |x  |\n",
    "| x |x  |\n",
    "| x |x  |\n",
    "\n",
    "### Table: **user_years_elite**\n",
    "\n",
    "|user_id|year|\n",
    "|-------|----|\n",
    "| x |x  |\n",
    "| x |x  |\n",
    "| x |x  |\n",
    "\n",
    "### Table: **user_complements**\n",
    "\n",
    "|user_id|compliment_type|count|\n",
    "|-------|---------------|-----|\n",
    "| x | x |x |\n",
    "| x | x |x |\n",
    "| x | x |x |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to create the following HIVE table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:42:53.323193",
     "start_time": "2017-01-21T00:42:53.231219"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    user_id STRING,\n",
    "    name STRING,\n",
    "    review_count INT,\n",
    "    average_stars DOUBLE,\n",
    "    yelping_since,\n",
    "    fans INT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a MapReduce mapper script that transforms records from the 'user' data set to the above format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:34:03.705696",
     "start_time": "2017-01-21T00:34:03.698742"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load users2csv_mpr.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import json\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    try:\n",
    "        r = json.loads(line.strip())\n",
    "        print ','.join([r['user_id'], r['name'], r['review_count'], r['average_stars'], r['yelping_since'], r['fans'] ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... run MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:49:18.889803",
     "start_time": "2017-01-21T00:48:54.734740"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/pmolnar/yelp/output/users2csv\n",
      "packageJobJar: [] [/usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar] /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir/streamjob7721050826789992328.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17/01/21 00:48:59 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 00:48:59 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 00:49:00 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 00:49:00 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 00:49:00 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "17/01/21 00:49:00 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "17/01/21 00:49:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484597252711_0134\n",
      "17/01/21 00:49:01 INFO impl.YarnClientImpl: Submitted application application_1484597252711_0134\n",
      "17/01/21 00:49:01 INFO mapreduce.Job: The url to track the job: http://backend-0-1.insight.gsu.edu:8088/proxy/application_1484597252711_0134/\n",
      "17/01/21 00:49:01 INFO mapreduce.Job: Running job: job_1484597252711_0134\n",
      "17/01/21 00:49:06 INFO mapreduce.Job: Job job_1484597252711_0134 running in uber mode : false\n",
      "17/01/21 00:49:06 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "17/01/21 00:49:13 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "17/01/21 00:49:17 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "17/01/21 00:49:18 INFO mapreduce.Job: Job job_1484597252711_0134 completed successfully\n",
      "17/01/21 00:49:18 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3587964\n",
      "\t\tFILE: Number of bytes written=7451109\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12280325\n",
      "\t\tHDFS: Number of bytes written=3450808\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4658\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=5024\n",
      "\t\tTotal time spent by all map tasks (ms)=4658\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2512\n",
      "\t\tTotal vcore-seconds taken by all map tasks=4658\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2512\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=38158336\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=41156608\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=68655\n",
      "\t\tMap output records=68575\n",
      "\t\tMap output bytes=3450808\n",
      "\t\tMap output materialized bytes=3587964\n",
      "\t\tInput split bytes=135\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=68575\n",
      "\t\tReduce shuffle bytes=3587964\n",
      "\t\tReduce input records=68575\n",
      "\t\tReduce output records=68575\n",
      "\t\tSpilled Records=137150\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=138\n",
      "\t\tCPU time spent (ms)=5850\n",
      "\t\tPhysical memory (bytes) snapshot=2945843200\n",
      "\t\tVirtual memory (bytes) snapshot=25415426048\n",
      "\t\tTotal committed heap usage (bytes)=3383754752\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=12280190\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3450808\n",
      "17/01/21 00:49:18 INFO streaming.StreamJob: Output directory: /user/pmolnar/yelp/output/users2csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# use the current directory as location for program files\n",
    "WD=`pwd`\n",
    "\n",
    "OUTDIR=/user/$USER/yelp/output\n",
    "OUTPUT=$OUTDIR/users2csv\n",
    "\n",
    "# make sure output directory exists\n",
    "hdfs dfs -mkdir -p $OUTDIR \n",
    "\n",
    "# make sure the output files don't exist\n",
    "hdfs dfs -rm -r -f -skipTrash $OUTPUT\n",
    "\n",
    "INPUT=/user/pmolnar/yelp/data/user/*\n",
    "yarn \\\n",
    "    jar /usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar \\\n",
    "    -mapper \"$WD/users2csv_mpr.py\" \\\n",
    "    -input $INPUT \\\n",
    "    -output $OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the output of the mapreduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:49:27.416607",
     "start_time": "2017-01-21T00:49:25.496131"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 00:49 /user/pmolnar/yelp/output/users2csv/_SUCCESS\n",
      "-rw-r--r--   3 pmolnar hadoop    3450808 2017-01-21 00:49 /user/pmolnar/yelp/output/users2csv/part-00000\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls /user/pmolnar/yelp/output/users2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:49:32.792786",
     "start_time": "2017-01-21T00:49:32.587225"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "LOAD DATA INPATH '/user/pmolnar/yelp/output/users2csv/part-*' INTO TABLE users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T00:49:36.877103",
     "start_time": "2017-01-21T00:49:36.749972"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>users.user_id</th>\n",
       "        <th>users.name</th>\n",
       "        <th>users.review_count</th>\n",
       "        <th>users.average_stars</th>\n",
       "        <th>users.yelping_since</th>\n",
       "        <th>users.fans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--2QZsyXGz1OhiD4-0FQLQ</td>\n",
       "        <td>Kay</td>\n",
       "        <td>7</td>\n",
       "        <td>4.86</td>\n",
       "        <td>2014-04-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--519Rh5sTtkoUraGzAaKQ</td>\n",
       "        <td>Eric</td>\n",
       "        <td>8</td>\n",
       "        <td>4.5</td>\n",
       "        <td>2014-12-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--80yFOfe6nZKLhxTMZjEg</td>\n",
       "        <td>Moe</td>\n",
       "        <td>8</td>\n",
       "        <td>4.12</td>\n",
       "        <td>2009-07-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--K8RaywcHmmFtIXIHKZJg</td>\n",
       "        <td>Susan</td>\n",
       "        <td>1</td>\n",
       "        <td>5.0</td>\n",
       "        <td>2013-04-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--LzFD0UDbYE-Oho3AhsOg</td>\n",
       "        <td>Shumai</td>\n",
       "        <td>133</td>\n",
       "        <td>3.9</td>\n",
       "        <td>2011-01-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--MJXewYKgIGpKvtfwBkfg</td>\n",
       "        <td>Jen</td>\n",
       "        <td>1</td>\n",
       "        <td>2.0</td>\n",
       "        <td>2014-04-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--VxRvXk3b8FwsSbC2Zpxw</td>\n",
       "        <td>B</td>\n",
       "        <td>41</td>\n",
       "        <td>4.44</td>\n",
       "        <td>2010-07-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--WHJIfhj7M-ntd65kUy7Q</td>\n",
       "        <td>Kadie</td>\n",
       "        <td>13</td>\n",
       "        <td>4.23</td>\n",
       "        <td>2010-07-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--ZBhtxi8VwI-x9GzCIyxw</td>\n",
       "        <td>Sharon</td>\n",
       "        <td>5</td>\n",
       "        <td>3.0</td>\n",
       "        <td>2012-04-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>--ZNzQbjx8FdCuJAkjl_vA</td>\n",
       "        <td>Anita</td>\n",
       "        <td>2</td>\n",
       "        <td>5.0</td>\n",
       "        <td>2012-07-01</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'--2QZsyXGz1OhiD4-0FQLQ', u'Kay', 7, 4.86, datetime.date(2014, 4, 1), None),\n",
       " (u'--519Rh5sTtkoUraGzAaKQ', u'Eric', 8, 4.5, datetime.date(2014, 12, 1), None),\n",
       " (u'--80yFOfe6nZKLhxTMZjEg', u'Moe', 8, 4.12, datetime.date(2009, 7, 1), None),\n",
       " (u'--K8RaywcHmmFtIXIHKZJg', u'Susan', 1, 5.0, datetime.date(2013, 4, 1), None),\n",
       " (u'--LzFD0UDbYE-Oho3AhsOg', u'Shumai', 133, 3.9, datetime.date(2011, 1, 1), None),\n",
       " (u'--MJXewYKgIGpKvtfwBkfg', u'Jen', 1, 2.0, datetime.date(2014, 4, 1), None),\n",
       " (u'--VxRvXk3b8FwsSbC2Zpxw', u'B', 41, 4.44, datetime.date(2010, 7, 1), None),\n",
       " (u'--WHJIfhj7M-ntd65kUy7Q', u'Kadie', 13, 4.23, datetime.date(2010, 7, 1), None),\n",
       " (u'--ZBhtxi8VwI-x9GzCIyxw', u'Sharon', 5, 3.0, datetime.date(2012, 4, 1), None),\n",
       " (u'--ZNzQbjx8FdCuJAkjl_vA', u'Anita', 2, 5.0, datetime.date(2012, 7, 1), None)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM pmolnar.users LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's create the remaining tables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:41:43.695361",
     "start_time": "2017-01-21T08:41:43.580474"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS user_votes (\n",
    "    user_id STRING,\n",
    "    vote_type STRING,\n",
    "    count INT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:41:46.185496",
     "start_time": "2017-01-21T08:41:46.085522"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS user_friends (\n",
    "    user_id STRING,\n",
    "    friends_user_id STRING\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:41:48.961501",
     "start_time": "2017-01-21T08:41:48.886844"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS user_years_elite (\n",
    "    user_id STRING,\n",
    "    year INT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:41:51.560511",
     "start_time": "2017-01-21T08:41:51.476654"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS user_compliments (\n",
    "    user_id STRING,\n",
    "    compliment_type STRING,\n",
    "    count INT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the MapReduce with the following mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:43:27.042338",
     "start_time": "2017-01-21T08:43:26.915333"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxr-x 1 pmolnar pmolnar 305 Jan 21 00:18 \u001b[0m\u001b[01;32muser_compliments2csv_mpr.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 pmolnar pmolnar 259 Jan 21 00:11 \u001b[01;32muser_friends2csv_mpr.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 pmolnar pmolnar 343 Jan 21 00:48 \u001b[01;32musers2csv_mpr.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 pmolnar pmolnar 293 Jan 21 00:07 \u001b[01;32muser_votes2csv_mpr.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 pmolnar pmolnar 262 Jan 21 00:15 \u001b[01;32muser_years_elite2csv_mpr.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls -l user*2csv_mpr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:48:05.708617",
     "start_time": "2017-01-21T08:46:32.355383"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table 'user_compliments'\n",
      "packageJobJar: [] [/usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar] /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir/streamjob6182295092184223707.jar tmpDir=null\n",
      "Creating table 'user_friends'\n",
      "packageJobJar: [] [/usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar] /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir/streamjob7413506657821228189.jar tmpDir=null\n",
      "Creating table 'user_votes'\n",
      "packageJobJar: [] [/usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar] /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir/streamjob1837506799785948537.jar tmpDir=null\n",
      "Creating table 'user_years_elite'\n",
      "packageJobJar: [] [/usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar] /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir/streamjob5081912236038291172.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17/01/21 08:46:37 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:46:37 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:46:37 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:46:37 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:46:38 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "17/01/21 08:46:38 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "17/01/21 08:46:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484597252711_0135\n",
      "17/01/21 08:46:38 INFO impl.YarnClientImpl: Submitted application application_1484597252711_0135\n",
      "17/01/21 08:46:38 INFO mapreduce.Job: The url to track the job: http://backend-0-1.insight.gsu.edu:8088/proxy/application_1484597252711_0135/\n",
      "17/01/21 08:46:38 INFO mapreduce.Job: Running job: job_1484597252711_0135\n",
      "17/01/21 08:46:43 INFO mapreduce.Job: Job job_1484597252711_0135 running in uber mode : false\n",
      "17/01/21 08:46:43 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "17/01/21 08:46:50 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "17/01/21 08:46:56 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "17/01/21 08:46:56 INFO mapreduce.Job: Job job_1484597252711_0135 completed successfully\n",
      "17/01/21 08:46:56 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3089785\n",
      "\t\tFILE: Number of bytes written=6454795\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12280325\n",
      "\t\tHDFS: Number of bytes written=2907271\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4624\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=5784\n",
      "\t\tTotal time spent by all map tasks (ms)=4624\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2892\n",
      "\t\tTotal vcore-seconds taken by all map tasks=4624\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2892\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=37879808\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=47382528\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=68655\n",
      "\t\tMap output records=91254\n",
      "\t\tMap output bytes=2907271\n",
      "\t\tMap output materialized bytes=3089785\n",
      "\t\tInput split bytes=135\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=91254\n",
      "\t\tReduce shuffle bytes=3089785\n",
      "\t\tReduce input records=91254\n",
      "\t\tReduce output records=91254\n",
      "\t\tSpilled Records=182508\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=123\n",
      "\t\tCPU time spent (ms)=5710\n",
      "\t\tPhysical memory (bytes) snapshot=2942541824\n",
      "\t\tVirtual memory (bytes) snapshot=25416740864\n",
      "\t\tTotal committed heap usage (bytes)=3382706176\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=12280190\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2907271\n",
      "17/01/21 08:46:56 INFO streaming.StreamJob: Output directory: /user/pmolnar/yelp/output/user_compliments2csv\n",
      "17/01/21 08:46:59 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:46:59 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:00 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:47:00 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:00 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "17/01/21 08:47:00 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "17/01/21 08:47:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484597252711_0136\n",
      "17/01/21 08:47:01 INFO impl.YarnClientImpl: Submitted application application_1484597252711_0136\n",
      "17/01/21 08:47:01 INFO mapreduce.Job: The url to track the job: http://backend-0-1.insight.gsu.edu:8088/proxy/application_1484597252711_0136/\n",
      "17/01/21 08:47:01 INFO mapreduce.Job: Running job: job_1484597252711_0136\n",
      "17/01/21 08:47:06 INFO mapreduce.Job: Job job_1484597252711_0136 running in uber mode : false\n",
      "17/01/21 08:47:06 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "17/01/21 08:47:14 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "17/01/21 08:47:20 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "17/01/21 08:47:20 INFO mapreduce.Job: Job job_1484597252711_0136 completed successfully\n",
      "17/01/21 08:47:20 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=25813696\n",
      "\t\tFILE: Number of bytes written=51902601\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12280325\n",
      "\t\tHDFS: Number of bytes written=24760070\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5554\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=7358\n",
      "\t\tTotal time spent by all map tasks (ms)=5554\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3679\n",
      "\t\tTotal vcore-seconds taken by all map tasks=5554\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3679\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=45498368\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=60276736\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=68655\n",
      "\t\tMap output records=526810\n",
      "\t\tMap output bytes=24760070\n",
      "\t\tMap output materialized bytes=25813696\n",
      "\t\tInput split bytes=135\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=526810\n",
      "\t\tReduce shuffle bytes=25813696\n",
      "\t\tReduce input records=526810\n",
      "\t\tReduce output records=526810\n",
      "\t\tSpilled Records=1053620\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=150\n",
      "\t\tCPU time spent (ms)=8370\n",
      "\t\tPhysical memory (bytes) snapshot=3049902080\n",
      "\t\tVirtual memory (bytes) snapshot=25418203136\n",
      "\t\tTotal committed heap usage (bytes)=3399483392\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=12280190\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=24760070\n",
      "17/01/21 08:47:20 INFO streaming.StreamJob: Output directory: /user/pmolnar/yelp/output/user_friends2csv\n",
      "17/01/21 08:47:24 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:47:24 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:24 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:47:24 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:25 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "17/01/21 08:47:25 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "17/01/21 08:47:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484597252711_0137\n",
      "17/01/21 08:47:25 INFO impl.YarnClientImpl: Submitted application application_1484597252711_0137\n",
      "17/01/21 08:47:25 INFO mapreduce.Job: The url to track the job: http://backend-0-1.insight.gsu.edu:8088/proxy/application_1484597252711_0137/\n",
      "17/01/21 08:47:25 INFO mapreduce.Job: Running job: job_1484597252711_0137\n",
      "17/01/21 08:47:30 INFO mapreduce.Job: Job job_1484597252711_0137 running in uber mode : false\n",
      "17/01/21 08:47:30 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "17/01/21 08:47:37 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "17/01/21 08:47:43 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "17/01/21 08:47:43 INFO mapreduce.Job: Job job_1484597252711_0137 completed successfully\n",
      "17/01/21 08:47:43 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=7070479\n",
      "\t\tFILE: Number of bytes written=14416167\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12280325\n",
      "\t\tHDFS: Number of bytes written=6658543\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4628\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=6154\n",
      "\t\tTotal time spent by all map tasks (ms)=4628\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3077\n",
      "\t\tTotal vcore-seconds taken by all map tasks=4628\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3077\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=37912576\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=50413568\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=68655\n",
      "\t\tMap output records=205965\n",
      "\t\tMap output bytes=6658543\n",
      "\t\tMap output materialized bytes=7070479\n",
      "\t\tInput split bytes=135\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=205965\n",
      "\t\tReduce shuffle bytes=7070479\n",
      "\t\tReduce input records=205965\n",
      "\t\tReduce output records=205965\n",
      "\t\tSpilled Records=411930\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=140\n",
      "\t\tCPU time spent (ms)=6480\n",
      "\t\tPhysical memory (bytes) snapshot=2981175296\n",
      "\t\tVirtual memory (bytes) snapshot=25425448960\n",
      "\t\tTotal committed heap usage (bytes)=3408396288\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=12280190\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6658543\n",
      "17/01/21 08:47:43 INFO streaming.StreamJob: Output directory: /user/pmolnar/yelp/output/user_votes2csv\n",
      "17/01/21 08:47:46 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:47:46 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:47 INFO impl.TimelineClientImpl: Timeline service address: http://backend-0-2.insight.gsu.edu:8188/ws/v1/timeline/\n",
      "17/01/21 08:47:47 INFO client.RMProxy: Connecting to ResourceManager at backend-0-1.insight.gsu.edu/192.168.1.253:8050\n",
      "17/01/21 08:47:47 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "17/01/21 08:47:47 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "17/01/21 08:47:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484597252711_0138\n",
      "17/01/21 08:47:47 INFO impl.YarnClientImpl: Submitted application application_1484597252711_0138\n",
      "17/01/21 08:47:47 INFO mapreduce.Job: The url to track the job: http://backend-0-1.insight.gsu.edu:8088/proxy/application_1484597252711_0138/\n",
      "17/01/21 08:47:47 INFO mapreduce.Job: Running job: job_1484597252711_0138\n",
      "17/01/21 08:47:53 INFO mapreduce.Job: Job job_1484597252711_0138 running in uber mode : false\n",
      "17/01/21 08:47:53 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "17/01/21 08:47:59 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "17/01/21 08:48:04 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "17/01/21 08:48:05 INFO mapreduce.Job: Job job_1484597252711_0138 completed successfully\n",
      "17/01/21 08:48:05 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=535221\n",
      "\t\tFILE: Number of bytes written=1345667\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12280325\n",
      "\t\tHDFS: Number of bytes written=500685\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4246\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=5054\n",
      "\t\tTotal time spent by all map tasks (ms)=4246\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2527\n",
      "\t\tTotal vcore-seconds taken by all map tasks=4246\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2527\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=34783232\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=41402368\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=68655\n",
      "\t\tMap output records=17265\n",
      "\t\tMap output bytes=500685\n",
      "\t\tMap output materialized bytes=535221\n",
      "\t\tInput split bytes=135\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=17265\n",
      "\t\tReduce shuffle bytes=535221\n",
      "\t\tReduce input records=17265\n",
      "\t\tReduce output records=17265\n",
      "\t\tSpilled Records=34530\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=137\n",
      "\t\tCPU time spent (ms)=5040\n",
      "\t\tPhysical memory (bytes) snapshot=2916970496\n",
      "\t\tVirtual memory (bytes) snapshot=25422655488\n",
      "\t\tTotal committed heap usage (bytes)=3413639168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=12280190\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=500685\n",
      "17/01/21 08:48:05 INFO streaming.StreamJob: Output directory: /user/pmolnar/yelp/output/user_years_elite2csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# use the current directory as location for program files\n",
    "WD=`pwd`\n",
    "\n",
    "OUTDIR=/user/$USER/yelp/output\n",
    "OUTPUT=$OUTDIR/users2csv\n",
    "\n",
    "# make sure output directory exists\n",
    "hdfs dfs -mkdir -p $OUTDIR \n",
    "\n",
    "for TAB in user_compliments user_friends user_votes user_years_elite; do\n",
    "    echo \"Creating table '$TAB'\"\n",
    "    \n",
    "    OUTPUT=$OUTDIR/${TAB}2csv\n",
    "    # make sure the output files don't exist\n",
    "    hdfs dfs -rm -r -f -skipTrash $OUTPUT\n",
    "\n",
    "    INPUT=/user/pmolnar/yelp/data/user/*\n",
    "    yarn \\\n",
    "        jar /usr/hdp/2.4.2.0-258/hadoop-mapreduce/hadoop-streaming-2.7.1.2.4.2.0-258.jar \\\n",
    "        -mapper \"$WD/${TAB}2csv_mpr.py\" \\\n",
    "        -input $INPUT \\\n",
    "        -output $OUTPUT\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T09:06:42.303441",
     "start_time": "2017-01-21T09:06:40.416099"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-15 14:35 /user/pmolnar/yelp/output/business_by_city\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-15 14:35 /user/pmolnar/yelp/output/business_by_city/_SUCCESS\n",
      "-rw-r--r--   3 pmolnar hadoop      10636 2017-01-15 14:35 /user/pmolnar/yelp/output/business_by_city/part-00000\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-15 21:22 /user/pmolnar/yelp/output/checkin_by_city\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-15 21:22 /user/pmolnar/yelp/output/checkin_by_city/_SUCCESS\n",
      "-rw-r--r--   3 pmolnar hadoop     413406 2017-01-15 21:22 /user/pmolnar/yelp/output/checkin_by_city/part-00000\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-15 21:21 /user/pmolnar/yelp/output/checkin_join\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-15 21:21 /user/pmolnar/yelp/output/checkin_join/_SUCCESS\n",
      "-rw-r--r--   3 pmolnar hadoop   89505143 2017-01-15 21:21 /user/pmolnar/yelp/output/checkin_join/part-00000\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 00:28 /user/pmolnar/yelp/output/user2csv\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 08:52 /user/pmolnar/yelp/output/user_compliments2csv\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 08:46 /user/pmolnar/yelp/output/user_compliments2csv/_SUCCESS\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 08:52 /user/pmolnar/yelp/output/user_friends2csv\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 08:47 /user/pmolnar/yelp/output/user_friends2csv/_SUCCESS\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 08:52 /user/pmolnar/yelp/output/user_votes2csv\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 08:47 /user/pmolnar/yelp/output/user_votes2csv/_SUCCESS\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 08:52 /user/pmolnar/yelp/output/user_years_elite2csv\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 08:48 /user/pmolnar/yelp/output/user_years_elite2csv/_SUCCESS\n",
      "drwxr-xr-x   - pmolnar hadoop          0 2017-01-21 00:49 /user/pmolnar/yelp/output/users2csv\n",
      "-rw-r--r--   3 pmolnar hadoop          0 2017-01-21 00:49 /user/pmolnar/yelp/output/users2csv/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls -R /user/pmolnar/yelp/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and load into Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T09:05:15.130762",
     "start_time": "2017-01-21T09:05:15.121687"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sa.create_engine('hive://backend-0-1:10000/pmolnar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T09:05:37.976204",
     "start_time": "2017-01-21T09:05:37.804107"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DATA INPATH '/user/pmolnar/yelp/output/user_compliments2csv/part-*' INTO TABLE pmolnar.user_compliments\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(pyhive.exc.OperationalError) TExecuteStatementResp(status=TStatus(errorCode=40000, errorMessage=\"Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*\", sqlState='42000', infoMessages=[\"*org.apache.hive.service.cli.HiveSQLException:Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*:28:27\", 'org.apache.hive.service.cli.operation.Operation:toSQLException:Operation.java:315', 'org.apache.hive.service.cli.operation.SQLOperation:prepare:SQLOperation.java:112', 'org.apache.hive.service.cli.operation.SQLOperation:runInternal:SQLOperation.java:181', 'org.apache.hive.service.cli.operation.Operation:run:Operation.java:257', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatementInternal:HiveSessionImpl.java:419', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatement:HiveSessionImpl.java:400', 'sun.reflect.GeneratedMethodAccessor23:invoke::-1', 'sun.reflect.DelegatingMethodAccessorImpl:invoke:DelegatingMethodAccessorImpl.java:43', 'java.lang.reflect.Method:invoke:Method.java:497', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:78', 'org.apache.hive.service.cli.session.HiveSessionProxy:access$000:HiveSessionProxy.java:36', 'org.apache.hive.service.cli.session.HiveSessionProxy$1:run:HiveSessionProxy.java:63', 'java.security.AccessController:doPrivileged:AccessController.java:-2', 'javax.security.auth.Subject:doAs:Subject.java:422', 'org.apache.hadoop.security.UserGroupInformation:doAs:UserGroupInformation.java:1709', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:59', 'com.sun.proxy.$Proxy22:executeStatement::-1', 'org.apache.hive.service.cli.CLIService:executeStatement:CLIService.java:263', 'org.apache.hive.service.cli.thrift.ThriftCLIService:ExecuteStatement:ThriftCLIService.java:486', 'org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1317', 'org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1302', 'org.apache.thrift.ProcessFunction:process:ProcessFunction.java:39', 'org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39', 'org.apache.hive.service.auth.TSetIpAddressProcessor:process:TSetIpAddressProcessor.java:56', 'org.apache.thrift.server.TThreadPoolServer$WorkerProcess:run:TThreadPoolServer.java:285', 'java.util.concurrent.ThreadPoolExecutor:runWorker:ThreadPoolExecutor.java:1142', 'java.util.concurrent.ThreadPoolExecutor$Worker:run:ThreadPoolExecutor.java:617', 'java.lang.Thread:run:Thread.java:745', \"*org.apache.hadoop.hive.ql.parse.SemanticException:Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*:34:7\", 'org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer:applyConstraintsAndGetFiles:LoadSemanticAnalyzer.java:146', 'org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer:analyzeInternal:LoadSemanticAnalyzer.java:227', 'org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer:analyze:BaseSemanticAnalyzer.java:227', 'org.apache.hadoop.hive.ql.Driver:compile:Driver.java:459', 'org.apache.hadoop.hive.ql.Driver:compile:Driver.java:316', 'org.apache.hadoop.hive.ql.Driver:compileInternal:Driver.java:1189', 'org.apache.hadoop.hive.ql.Driver:compileAndRespond:Driver.java:1183', 'org.apache.hive.service.cli.operation.SQLOperation:prepare:SQLOperation.java:110'], statusCode=3), operationHandle=None) [SQL: \"LOAD DATA INPATH '/user/pmolnar/yelp/output/user_compliments2csv/part-*' INTO TABLE pmolnar.user_compliments\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-3465c94ebcf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LOAD DATA INPATH '/user/pmolnar/yelp/output/%s2csv/part-*' INTO TABLE pmolnar.%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTAB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   2053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \"\"\"\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m         )\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                 context)\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 util.raise_from_cause(\n\u001b[1;32m   1392\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m                     \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m                 )\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/util/compat.pyc\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                         \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                         context)\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             self._handle_dbapi_exception(\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/pyhive/hive.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, parameters, async)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecuteStatement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0m_check_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operationHandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperationHandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/pyhive/hive.pyc\u001b[0m in \u001b[0;36m_check_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatusCode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mttypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTStatusCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_STATUS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: (pyhive.exc.OperationalError) TExecuteStatementResp(status=TStatus(errorCode=40000, errorMessage=\"Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*\", sqlState='42000', infoMessages=[\"*org.apache.hive.service.cli.HiveSQLException:Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*:28:27\", 'org.apache.hive.service.cli.operation.Operation:toSQLException:Operation.java:315', 'org.apache.hive.service.cli.operation.SQLOperation:prepare:SQLOperation.java:112', 'org.apache.hive.service.cli.operation.SQLOperation:runInternal:SQLOperation.java:181', 'org.apache.hive.service.cli.operation.Operation:run:Operation.java:257', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatementInternal:HiveSessionImpl.java:419', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatement:HiveSessionImpl.java:400', 'sun.reflect.GeneratedMethodAccessor23:invoke::-1', 'sun.reflect.DelegatingMethodAccessorImpl:invoke:DelegatingMethodAccessorImpl.java:43', 'java.lang.reflect.Method:invoke:Method.java:497', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:78', 'org.apache.hive.service.cli.session.HiveSessionProxy:access$000:HiveSessionProxy.java:36', 'org.apache.hive.service.cli.session.HiveSessionProxy$1:run:HiveSessionProxy.java:63', 'java.security.AccessController:doPrivileged:AccessController.java:-2', 'javax.security.auth.Subject:doAs:Subject.java:422', 'org.apache.hadoop.security.UserGroupInformation:doAs:UserGroupInformation.java:1709', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:59', 'com.sun.proxy.$Proxy22:executeStatement::-1', 'org.apache.hive.service.cli.CLIService:executeStatement:CLIService.java:263', 'org.apache.hive.service.cli.thrift.ThriftCLIService:ExecuteStatement:ThriftCLIService.java:486', 'org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1317', 'org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1302', 'org.apache.thrift.ProcessFunction:process:ProcessFunction.java:39', 'org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39', 'org.apache.hive.service.auth.TSetIpAddressProcessor:process:TSetIpAddressProcessor.java:56', 'org.apache.thrift.server.TThreadPoolServer$WorkerProcess:run:TThreadPoolServer.java:285', 'java.util.concurrent.ThreadPoolExecutor:runWorker:ThreadPoolExecutor.java:1142', 'java.util.concurrent.ThreadPoolExecutor$Worker:run:ThreadPoolExecutor.java:617', 'java.lang.Thread:run:Thread.java:745', \"*org.apache.hadoop.hive.ql.parse.SemanticException:Line 1:17 Invalid path ''/user/pmolnar/yelp/output/user_compliments2csv/part-*'': No files matching path hdfs://backend-0-2.insight.gsu.edu:8020/user/pmolnar/yelp/output/user_compliments2csv/part-*:34:7\", 'org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer:applyConstraintsAndGetFiles:LoadSemanticAnalyzer.java:146', 'org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer:analyzeInternal:LoadSemanticAnalyzer.java:227', 'org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer:analyze:BaseSemanticAnalyzer.java:227', 'org.apache.hadoop.hive.ql.Driver:compile:Driver.java:459', 'org.apache.hadoop.hive.ql.Driver:compile:Driver.java:316', 'org.apache.hadoop.hive.ql.Driver:compileInternal:Driver.java:1189', 'org.apache.hadoop.hive.ql.Driver:compileAndRespond:Driver.java:1183', 'org.apache.hive.service.cli.operation.SQLOperation:prepare:SQLOperation.java:110'], statusCode=3), operationHandle=None) [SQL: \"LOAD DATA INPATH '/user/pmolnar/yelp/output/user_compliments2csv/part-*' INTO TABLE pmolnar.user_compliments\"]"
     ]
    }
   ],
   "source": [
    "for TAB in ['user_compliments', 'user_friends', 'user_votes', 'user_years_elite']:\n",
    "    q = \"LOAD DATA INPATH '/user/pmolnar/yelp/output/%s2csv/part-*' INTO TABLE pmolnar.%s\"%(TAB, TAB)\n",
    "    print q\n",
    "    res = conn.execute(q)\n",
    "    print '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "LOAD DATA INPATH '/user/pmolnar/yelp/output/$2csv/part-*' INTO TABLE pmolnar.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-21T08:55:09.666659",
     "start_time": "2017-01-21T08:55:09.546366"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>user_years_elite.user_id</th>\n",
       "        <th>user_years_elite.year</th>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM pmolnar.user_years_elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "toc": {
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
